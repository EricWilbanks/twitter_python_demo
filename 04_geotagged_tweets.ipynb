{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Geotags\n",
    "\n",
    "As we saw in `01_querying_twitter`, we can filter tweets that are geotagged within some radius of a particular location.\n",
    "\n",
    "**REMEMBER**: \n",
    "\n",
    "Twitter ToS strictly prohibits\n",
    "- separating geo information from the tweet it is attached to\n",
    "- using aggregated geo-information to track individuals or other movement\n",
    "\n",
    "Twitter ToS allows for \"Heat maps and related tools that show aggregated geo activity (e.g.,: the number of people in a city using a hashtag)\"\n",
    "\n",
    "## \"Beach\" Geodata\n",
    "`saved_searches/beach_tweets_extensive.csv` is 407 tweets that occurred in a circle roughly centered on the continental U.S. and which included the word \"beach\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import geopandas\n",
    "\n",
    "# load in tweet df; converters argument tells pandas to read the geo.coordinate column as an object (list) not a string\n",
    "beach_tweets = pd.read_csv('saved_searches/beach_tweets_extensive.csv', converters = {'geo.coordinates': eval})\n",
    "\n",
    "# add columns for long and lat\n",
    "beach_tweets[['geo.lat', 'geo.long']] = pd.DataFrame(beach_tweets['geo.coordinates'].to_list())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## geo.coordinates information\n",
    "\n",
    "Let's remind ourselves of the structure of the \"extensive\" tweet csv files which are the result of saving all of the .json information from our searches.\n",
    "\n",
    "The parameter of interest here is`geo.coordinates`, which is a list of the latitude and longitude of geo-tagged tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(beach_tweets.shape)\n",
    "print('\\n\\n\\n')\n",
    "print(beach_tweets['geo.coordinates'].describe())\n",
    "print('\\n\\n\\n')\n",
    "print(beach_tweets.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .shp files\n",
    "\n",
    "Shapefiles (.shp and associated files) are the standard format for representing digital maps.\n",
    "\n",
    "These files define the borders, polygons, and often metadata of various maps.\n",
    "\n",
    "There exist **many** free and open-source Shapefiles for nations, cities, and specialized purposes. You can even create your own Shapefiles files if you learn GIS software.\n",
    "\n",
    "<br />\n",
    "<br />\n",
    "\n",
    "We're going to use the python library `geopandas` to manipulate Shapefiles from the US Census and layer our tweet data on-top of this map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape files from US census https://www.census.gov/geographies/mapping-files/time-series/geo/carto-boundary-file.html\n",
    "states = geopandas.read_file('us_state_data/cb_2018_us_state_500k.shp')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(25,50)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_ylim([25,50])\n",
    "ax.set_xlim([-125,-67])\n",
    "\n",
    "states.plot(ax = ax, color = 'white', edgecolor = 'black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flexible Approach\n",
    "\n",
    "There are an incredible number of flexible options in both `geopandas` and `matplotlib` that we're not going to be able to get into. \n",
    "\n",
    "I've linked to some resources in the README which demonstrate how powerful these tools are together.\n",
    "\n",
    "## Plotting Geo-Tagged Tweets\n",
    "\n",
    "Let's content ourselves with just adding points for our geo-tagged tweets as a layer on our US shapefile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert long/lat from beach_tweets into a geoDataframe\n",
    "gdf = geopandas.GeoDataFrame(beach_tweets, geometry = geopandas.points_from_xy(beach_tweets['geo.long'], beach_tweets['geo.lat']))\n",
    "\n",
    "# shape files from US census https://www.census.gov/geographies/mapping-files/time-series/geo/carto-boundary-file.html\n",
    "states = geopandas.read_file('us_state_data/cb_2018_us_state_500k.shp')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(25,50)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_ylim([25,50])\n",
    "ax.set_xlim([-125,-67])\n",
    "\n",
    "states.plot(ax = ax, color = 'white', edgecolor = 'black')\n",
    "gdf.plot(ax = ax, color = 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Tweet Density\n",
    "\n",
    "Single-size dots aren't giving us a great idea of the true picture, especially since there might be many tweets sent from the same location with overlapping points.\n",
    "\n",
    "Let's set the point marker size to relative to the number of tweets that came from the same location!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing some pandas shenanigans to create a count of each unique geo_coordinates value\n",
    "# since geo.coordinates' values are lists, we'll convert them to tuple to be able to count them\n",
    "# our count column is named 'geo.count'\n",
    "geo_count_df = beach_tweets.groupby(beach_tweets['geo.coordinates'].map(tuple)).size().reset_index(name='geo.count')\n",
    "print(geo_count_df.head())\n",
    "\n",
    "# temporarily change geo.coordinates to tuple to match\n",
    "beach_tweets['geo.coordinates'] = beach_tweets['geo.coordinates'].map(tuple)\n",
    "\n",
    "# create a new df (beach_tweets2) that matches the geo.count to each observation\n",
    "beach_tweets2 = pd.merge(beach_tweets, geo_count_df, on = 'geo.coordinates')\n",
    "\n",
    "# map both 'geo.coordinates' values from tuples back to lists\n",
    "geo_count_df['geo.coordinates'] = geo_count_df['geo.coordinates'].map(list)\n",
    "beach_tweets['geo.coordinates'] = beach_tweets['geo.coordinates'].map(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert long/lat from beach_tweets into a geoDataframe\n",
    "gdf = geopandas.GeoDataFrame(beach_tweets, geometry = geopandas.points_from_xy(beach_tweets['geo.long'], beach_tweets['geo.lat']))\n",
    "\n",
    "# set tweet marker size to the column we just created\n",
    "gdf['marker_size'] = beach_tweets2['geo.count']\n",
    "\n",
    "# shape files from US census https://www.census.gov/geographies/mapping-files/time-series/geo/carto-boundary-file.html\n",
    "states = geopandas.read_file('us_state_data/cb_2018_us_state_500k.shp')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(25,50)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_ylim([25,50])\n",
    "ax.set_xlim([-125,-67])\n",
    "\n",
    "states.plot(ax = ax, color = 'white', edgecolor = 'black')\n",
    "gdf.plot(ax = ax, color = 'teal', markersize = gdf['marker_size']*15, alpha = 0.35)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
