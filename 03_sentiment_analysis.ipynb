{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "With our new workflow for cleaning and processing text, let's see another example of the types of analyses we can perform on the data.\n",
    "\n",
    "**Sentiment Analysis** aims to automatically classify the emotional content or sentiment of a given piece of information. The most common use case is automatically classifying text social media posts as positive or negative.\n",
    "\n",
    "A common approach is to do a full Part-Of-Speech parse on a large set of training data, then use machine learning to determine the features that best predict positivity or negativity in the training set. \n",
    "\n",
    "This approach uses machine learning techniques similar to what we discussed in our last workshop (in this case, often Naive Bayes Classifiers). \n",
    "\n",
    "\n",
    "For our *simple case today*, we'll be using a shortcut, the AFINN-111 wordlist that contains positive/negative valency ratings for around 2,500 English lexical items. This will allow us to estimate a rough positive to negative item ranking for each tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "# read in saved tweet searches and AFINN sentiment ratings\n",
    "trump_tweets = pd.read_csv('saved_searches/trump_tweets_extensive.csv')\n",
    "biden_tweets = pd.read_csv('saved_searches/biden_tweets_extensive.csv')\n",
    "sentim_ratings = pd.read_csv('AFINN/AFINN-111.txt', sep = '\\t', header = None, names = ['word', 'rating'])\n",
    "\n",
    "# redefine our cleaning function we developed in the last segment\n",
    "def clean_sentence(s, stopwords):\n",
    "    \"\"\"\n",
    "    Take as input a sentence as a str and a list of stopwords\n",
    "    Then output a tokenized, lower case list of all words which are not stopwords.\n",
    "    You could make this function more efficient by vectorizing it and then applying it to a pandas column simultaneously.\n",
    "    \"\"\"\n",
    "    s_tokenized = nltk.tokenize.word_tokenize(s)\n",
    "    s_lower = [w.lower() for w in s_tokenized]\n",
    "    s_words = [w for w in s_lower if w.isalpha()]\n",
    "    s_final = [w for w in s_words if not w in stopwords]\n",
    "    return s_final\n",
    "\n",
    "# define stopwords following nltk\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "# clean the tweet text from both trump and biden dfs\n",
    "trump_tweets['cleaned_text'] = trump_tweets.apply(lambda row: clean_sentence(row['text'], stopwords), axis = 1)\n",
    "biden_tweets['cleaned_text'] = biden_tweets.apply(lambda row: clean_sentence(row['text'], stopwords), axis = 1)\n",
    "\n",
    "# inspect various aspects to double-check our work\n",
    "print(sentim_ratings.head())\n",
    "print('\\n\\n')\n",
    "print(trump_tweets['text'][0])\n",
    "print(trump_tweets['cleaned_text'][0])\n",
    "print('\\n\\n')\n",
    "print(biden_tweets['text'][0])\n",
    "print(biden_tweets['cleaned_text'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method\n",
    "\n",
    "Our rough method for sentiment analysis will take the following steps:\n",
    "\n",
    "- Match all the words to sentiment values\n",
    "- If a word doesn't have a match, give it a value of 0\n",
    "- Divide the total sentiment rating by the number of words\n",
    "\n",
    "**As we work through one example, consider in what ways this can be inaccurate?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_sentiment(s, ratings):\n",
    "    \"\"\"\n",
    "    takes a list (s) of lowercase words and matches them to the pandas df ratings ('word' and 'rating' columns)\n",
    "    returns a normalized overall sentiment value\n",
    "    \"\"\"\n",
    "    value = 0\n",
    "    # looping over words in list s; lots of room to make this more efficient\n",
    "    for word in s:\n",
    "        # test if word is in our set of rated words\n",
    "        if ratings['word'].isin([word]).any():\n",
    "            # select matching value and extract as float\n",
    "            word_value = ratings.loc[ratings['word'] == word]['rating'].iloc[0]\n",
    "            # add this word_value to the sentence value\n",
    "            value += word_value\n",
    "    # normalize by length of tweet\n",
    "    return (value/len(s))\n",
    "\n",
    "trump_tweets['sentiment_value'] = trump_tweets.apply(lambda row: measure_sentiment(row['cleaned_text'], sentim_ratings), axis = 1)\n",
    "biden_tweets['sentiment_value'] = biden_tweets.apply(lambda row: measure_sentiment(row['cleaned_text'], sentim_ratings), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot and descriptive statistics\n",
    "fig, ax = plt.subplots(1,1)\n",
    "plt.boxplot([trump_tweets['sentiment_value'], biden_tweets['sentiment_value']])\n",
    "plt.xticks([1,2], ['trump','biden'])\n",
    "ax.axhline(y=0)\n",
    "plt.show()\n",
    "\n",
    "print(trump_tweets['sentiment_value'].describe())\n",
    "print()\n",
    "print(biden_tweets['sentiment_value'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all \"ambivalent\" tweets that have a value of 0\n",
    "trump_sub = trump_tweets[trump_tweets.sentiment_value != 0]\n",
    "biden_sub = biden_tweets[biden_tweets.sentiment_value != 0]\n",
    "\n",
    "# plot and descriptive statistics\n",
    "fig, ax = plt.subplots(1,1)\n",
    "plt.boxplot([trump_sub['sentiment_value'], biden_sub['sentiment_value']])\n",
    "plt.xticks([1,2], ['trump','biden'])\n",
    "ax.axhline(y=0)\n",
    "plt.show()\n",
    "\n",
    "print(trump_sub['sentiment_value'].describe())\n",
    "print()\n",
    "print(biden_sub['sentiment_value'].describe())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
